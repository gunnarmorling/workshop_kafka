 -- create 4 Partition for topic carMultiPartition
./kafka-topics --create --topic carMultiPartition --replication-factor 1 --partitions 4 --zookeeper localhost:2181

./kafka-topics --create --topic MyStringPartition --replication-factor 1 --partitions 5 --zookeeper localhost:2181

 -- show available topics
./kafka-topics --list --zookeeper localhost:2181


 -- describe topics
./kafka-topics.sh --describe --zookeeper localhost:2181

-- send a lot of messages
./kafka-verifiable-producer --topic MyStringPartition --max-messages 2000 --broker-list localhost:9092

-- consume messages
./kafka-console-consumer --topic MyStringPartition --partition 0 --bootstrap-server localhost:9092

-- show consumer lag
kafka-consumer-groups --describe --group CatchTheString --bootstrap-server localhost:9092

Download the 0.11.0.0 release and un-tar it.
1
2
> tar -xzf kafka_2.11-0.11.0.0.tgz
> cd kafka_2.11-0.11.0.0
Step 2: Start the server

Kafka uses ZooKeeper so you need to first start a ZooKeeper server if you don't already have one. You can use the convenience script packaged with kafka to get a quick-and-dirty single-node ZooKeeper instance.

1
2
3
> bin/zookeeper-server-start.sh config/zookeeper.properties
[2013-04-22 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
Now start the Kafka server:

1
2
3
4
> bin/kafka-server-start.sh config/server.properties
[2013-04-22 15:01:47,028] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2013-04-22 15:01:47,051] INFO Property socket.send.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiableProperties)
...
Step 3: Create a topic

Let's create a topic named "test" with a single partition and only one replica:

1
> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
We can now see that topic if we run the list topic command:

1
2
> bin/kafka-topics.sh --list --zookeeper localhost:2181
test
Alternatively, instead of manually creating topics you can also configure your brokers to auto-create topics when a non-existent topic is published to.

Step 4: Send some messages

Kafka comes with a command line client that will take input from a file or from standard input and send it out as messages to the Kafka cluster. By default, each line will be sent as a separate message.

Run the producer and then type a few messages into the console to send to the server.

1
2
3
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
This is a message
This is another message
Step 5: Start a consumer

Kafka also has a command line consumer that will dump out messages to standard output.

1
2
3
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
This is a message
This is another message